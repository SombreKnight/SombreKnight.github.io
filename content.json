{"meta":{"title":"张晨曦的博客","subtitle":"个人博客","description":"技术分享 工作心得 生活感悟","author":"张晨曦","url":"https://sombreknight.gitee.io","root":"/"},"pages":[{"title":"分类","date":"2021-01-09T02:59:20.699Z","updated":"2021-01-09T02:59:20.699Z","comments":false,"path":"index.html","permalink":"https://sombreknight.gitee.io/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2021-01-09T03:02:07.343Z","updated":"2021-01-09T03:02:07.343Z","comments":false,"path":"/404.html","permalink":"https://sombreknight.gitee.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2021-01-09T06:23:36.265Z","updated":"2021-01-09T06:23:36.257Z","comments":false,"path":"about/index.html","permalink":"https://sombreknight.gitee.io/about/index.html","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&#123; &quot;name&quot;: &quot;张晨曦&quot;, &quot;age&quot;: 24, &quot;profession&quot;: &quot;Java Developer&quot;, &quot;experience&quot;: &quot;2年&quot;, &quot;address&quot;: &quot;四川省成都市&quot;, &quot;education&quot;: &quot;本科&quot;, &quot;github&quot;: &quot;https://github.com/SombreKnight&quot;, &quot;blog&quot;: &quot;https://sombreknight.github.io&quot;, &quot;email&quot;: &quot;dlmu_zhangchenxi@foxmail.com&quot;, &quot;description&quot;: &quot;五年开发经验的两年Java工程师&quot;, &quot;skills&quot;: &#123; &quot;Java&quot;: [ &quot;Basic Java&quot;, &quot;Java Collection&quot;, &quot;Java IO&quot;, &quot;Java Concurrent&quot;, &quot;JVM &amp; GC&quot; ], &quot;Web FrameWork&quot;: [ &quot;Spring&quot;, &quot;SpringMVC&quot;, &quot;SpringBoot&quot; ], &quot;SpringCloud&quot;: [ &quot;Eureka&quot;, &quot;Ribbon&quot;, &quot;Open Feign&quot;, &quot;Hystrix&quot;, &quot;GateWay&quot; ], &quot;SpringCloudAlibaba&quot;: [ &quot;Nacos&quot;, &quot;Sentinel&quot;, &quot;Dubbo&quot;, &quot;Seata&quot; ], &quot;Web Security&quot;: [ &quot;XSS&quot;, &quot;CSRF&quot;, &quot;SQL injection&quot;, &quot;Upload vulnerability&quot;, &quot;Download vulnerability&quot;, &quot;Url Jump vulnerability&quot; ], &quot;MiddleWare&quot;: [ &quot;Redis&quot;, &quot;Zookeeper&quot;, &quot;RabbitMQ&quot;, &quot;Kafka&quot; ], &quot;Software Engineering&quot;: [ &quot;Design Parttern&quot;, &quot;Code Clean Way&quot;, &quot;Refactor&quot;, &quot;DDD&quot; ], &quot;Linux&quot;: [ &quot;basic cmd&quot;, &quot;shell&quot;, &quot;basic ops skills&quot; ], &quot;BigData&quot;: [ &quot;Hadoop&quot;, &quot;Spark&quot;, &quot;Flink&quot; ], &quot;Others&quot;: [ &quot;SVN&quot;, &quot;GIT&quot;, &quot;Maven&quot;, &quot;Docker&quot;, &quot;ELK&quot;, &quot;Python&quot;, &quot;Php&quot;, &quot;JavaScript&quot;, &quot;VUE&quot; ] &#125;&#125;"},{"title":"分类","date":"2021-01-09T03:00:41.011Z","updated":"2021-01-09T03:00:41.011Z","comments":false,"path":"categories/index.html","permalink":"https://sombreknight.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-01-23T15:41:26.940Z","updated":"2021-01-23T15:41:26.935Z","comments":true,"path":"links/index.html","permalink":"https://sombreknight.gitee.io/links/index.html","excerpt":"","text":""},{"title":"项目","date":"2021-01-09T06:50:06.768Z","updated":"2021-01-09T06:50:06.760Z","comments":false,"path":"repository/index.html","permalink":"https://sombreknight.gitee.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-01-09T02:59:59.946Z","updated":"2021-01-09T02:59:59.946Z","comments":false,"path":"tags/index.html","permalink":"https://sombreknight.gitee.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java虚拟机的体系结构---运行时数据区","slug":"TwKQVMOtQ3nL1Dry","date":"2021-02-20T07:44:10.000Z","updated":"2021-02-20T07:44:15.000Z","comments":true,"path":"2021/02/20/TwKQVMOtQ3nL1Dry/","link":"","permalink":"https://sombreknight.gitee.io/2021/02/20/TwKQVMOtQ3nL1Dry/","excerpt":"","text":"官方文档：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html 一、宏观角度 Java虚拟机规范中对于虚拟机结构的描述大概分为以下几个方面： 关于class文件格式(The class file format) 数据类型（Data Type） 原始类型和值（Primitive Types and Values） 参考类型和值（Reference Types and Values） 运行时数据区（Run-Time Data Areas） 帧（Frames） 对象的表示（Representation of Objects） 浮点运算（ Floating-Point Arithmetic） 特殊方法（Special Methods） 异常（Exception） 指令集概览（Instruction Set Summary） 类库（Class Libraries） 公共设计与私有实现（Public Design, Private Implementation） 故如果可以遵循这些Java虚拟机的规范去设计，就可以正确的实现一个执行JVM语系的语言的解释平台。这里只对比较关键的部分Java虚拟机规范进行深入学习，以提升自己的视野，从更底层的角度了解Java虚拟机的工作原理。 二、运行时数据区关于Java虚拟机中的运行时数据区，规范中这样描述： The Java Virtual Machine defines various run-time data areas that are used during execution of a program. Some of these data areas are created on Java Virtual Machine start-up and are destroyed only when the Java Virtual Machine exits. Other data areas are per thread. Per-thread data areas are created when a thread is created and destroyed when the thread exits. 翻译过来就是： Java虚拟机定义了在程序执行期间使用的各种运行时数据区域。其中一些数据区域是在Java虚拟机启动时创建的，只有在Java虚拟机退出时才会被销毁。其他数据区域是每个线程的。每线程数据区域在创建线程时创建，在线程退出时销毁。 至此，大概清楚了Java虚拟机对于程序执行期间所使用的运行时数据区大概是分成了两个部分： 公共的运行时数据区：随虚拟机启动而创建，随虚拟机退出而销毁 每个线程所使用的运行时数据区：随线程创建时创建，随线程退出时而销毁 继续深入，深入前先看下目录，对于运行时数据区，官方文档这样定义了目录： 所以我们现在大概知道了运行时数据区的组成： 1. PC寄存器（program counter register 程序计数器）官方介绍： The Java Virtual Machine can support many threads of execution at once (JLS §17). Each Java Virtual Machine thread has its own pc (program counter) register. At any point, each Java Virtual Machine thread is executing the code of a single method, namely the current method (§2.6) for that thread. If that method is not native, the pc register contains the address of the Java Virtual Machine instruction currently being executed. If the method currently being executed by the thread is native, the value of the Java Virtual Machine’s pc register is undefined. The Java Virtual Machine’s pc register is wide enough to hold a returnAddress or a native pointer on the specific platform. 翻译过来就是： Java虚拟机可以同时支持多个执行线程。每个Java虚拟机线程都有自己的pc（程序计数器）寄存器。在任何时候，每个Java虚拟机线程都在执行单个方法的代码，即该线程的当前方法。如果该方法不是Native方法，则pc寄存器包含当前正在执行的Java虚拟机指令的地址。如果线程当前执行的方法是Native方法，则Java虚拟机的pc寄存器的值是未定义的。Java虚拟机的pc寄存器足够宽，可以容纳特定平台上的返回地址或本机指针。 总结： PC寄存器就是运行时数据区中生命周期与线程关联的部分。每个线程的PC寄存器上记录了正在执行的Java虚拟机指令地址，但如果当前线程执行的是Native方法，PC寄存器上的值就是未定义。 2. Java虚拟机栈（Java Virtual Machine Stacks）官方介绍： Each Java Virtual Machine thread has a private Java Virtual Machine stack, created at the same time as the thread. A Java Virtual Machine stack stores frames (§2.6). A Java Virtual Machine stack is analogous to the stack of a conventional language such as C: it holds local variables and partial results, and plays a part in method invocation and return. Because the Java Virtual Machine stack is never manipulated directly except to push and pop frames, frames may be heap allocated. The memory for a Java Virtual Machine stack does not need to be contiguous. In the First Edition of The Java® Virtual Machine Specification, the Java Virtual Machine stack was known as the Java stack. This specification permits Java Virtual Machine stacks either to be of a fixed size or to dynamically expand and contract as required by the computation. If the Java Virtual Machine stacks are of a fixed size, the size of each Java Virtual Machine stack may be chosen independently when that stack is created. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of Java Virtual Machine stacks, as well as, in the case of dynamically expanding or contracting Java Virtual Machine stacks, control over the maximum and minimum sizes. The following exceptional conditions are associated with Java Virtual Machine stacks: If the computation in a thread requires a larger Java Virtual Machine stack than is permitted, the Java Virtual Machine throws a StackOverflowError. If Java Virtual Machine stacks can be dynamically expanded, and expansion is attempted but insufficient memory can be made available to effect the expansion, or if insufficient memory can be made available to create the initial Java Virtual Machine stack for a new thread, the Java Virtual Machine throws an OutOfMemoryError. 翻译过来就是： 每个Java虚拟机线程都有一个与线程同时创建的私有Java虚拟机栈。Java虚拟机栈存储“栈帧”。Java虚拟机栈类似于传统语言（如C）的堆栈：它保存局部变量和部分结果，并在方法调用和返回中起作用。因为除了推送和弹出帧之外，Java虚拟机栈从不被直接操作，所以帧可以被堆分配。Java虚拟机栈的内存不需要是连续的。 在Java虚拟机规范的第一版中，Java虚拟机栈被称为Java栈（Java Stack）。 这个规范允许Java虚拟机栈具有固定的大小，或者根据计算的需要动态地扩展和收缩。如果Java虚拟机栈的大小是固定的，则在创建该堆栈时，可以独立选择每个Java虚拟机堆栈的大小。 Java虚拟机实现可以向程序员或用户提供对Java虚拟机栈的初始大小的控制，以及在动态扩展或收缩Java虚拟机栈的情况下，控制最大和最小大小。 以下异常情况与Java虚拟机栈相关： 如果线程中的计算需要比允许的更大的Java虚拟机栈，则Java虚拟机抛出stackoverflower。 如果可以动态扩展Java虚拟机栈，并且尝试扩展，但无法提供足够的内存来实现扩展，或者如果内存不足，无法为新线程创建初始Java虚拟机栈，则Java虚拟机将抛出OutOfMemoryError。 总结：Java虚拟机栈也是数据运行时数据区中与线程生命周期关联的部分。 Java虚拟机栈在第一版规范中也被叫做Java堆栈。 Java虚拟机栈的功能就是保存线程中的局部变了和部分结果，并且在方法调用和返回中起作用。Java虚拟机栈内存不需要是连续的。Java虚拟机栈可以设置固定大小，也可以动态扩展收缩。 3. 堆（Heap）官方介绍： The Java Virtual Machine has a heap that is shared among all Java Virtual Machine threads. The heap is the run-time data area from which memory for all class instances and arrays is allocated. The heap is created on virtual machine start-up. Heap storage for objects is reclaimed by an automatic storage management system (known as a garbage collector); objects are never explicitly deallocated. The Java Virtual Machine assumes no particular type of automatic storage management system, and the storage management technique may be chosen according to the implementor’s system requirements. The heap may be of a fixed size or may be expanded as required by the computation and may be contracted if a larger heap becomes unnecessary. The memory for the heap does not need to be contiguous. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the heap, as well as, if the heap can be dynamically expanded or contracted, control over the maximum and minimum heap size. The following exceptional condition is associated with the heap: If a computation requires more heap than can be made available by the automatic storage management system, the Java Virtual Machine throws an OutOfMemoryError. 翻译过来就是： Java虚拟机有一个堆，在所有Java虚拟机线程之间共享。堆是运行时数据区域，从中为所有类实例和数组分配内存。 堆是在虚拟机启动时创建的。对象的堆存储由自动存储管理系统（称为垃圾回收器）回收；对象从不显式释放。Java虚拟机不假设特定类型的自动存储管理系统，存储管理技术可以根据实现者的系统需求进行选择。堆可以是固定大小的，也可以根据计算的需要进行扩展，如果不需要更大的堆，则可以收缩堆。堆的内存不需要是连续的。 Java虚拟机实现可以让程序员或用户控制堆的初始大小，如果堆可以动态扩展或收缩，还可以控制堆的最大和最小大小。 以下异常情况与堆关联： 如果计算需要的堆超过了自动存储管理系统所能提供的堆，Java虚拟机将抛出OutOfMemoryError。 总结：Java虚拟机中的堆是运行时数据区中的公共部分，生命周期与虚拟机绑定，所有的线程可共享。主要功能就是为所有的类实例和数组分配内存。垃圾回收针对的就是这个堆内存区域。堆的大小可以是固定的，也可以动态扩展收缩。Java虚拟机不设定限制垃圾回收器，使用者可以自己根据实际的系统需求选择使用哪些垃圾回收器。 4. 方法区（Method Area）官方介绍： The Java Virtual Machine has a method area that is shared among all Java Virtual Machine threads. The method area is analogous to the storage area for compiled code of a conventional language or analogous to the “text” segment in an operating system process. It stores per-class structures such as the run-time constant pool, field and method data, and the code for methods and constructors, including the special methods (§2.9) used in class and instance initialization and interface initialization. The method area is created on virtual machine start-up. Although the method area is logically part of the heap, simple implementations may choose not to either garbage collect or compact it. This specification does not mandate the location of the method area or the policies used to manage compiled code. The method area may be of a fixed size or may be expanded as required by the computation and may be contracted if a larger method area becomes unnecessary. The memory for the method area does not need to be contiguous. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the method area, as well as, in the case of a varying-size method area, control over the maximum and minimum method area size. The following exceptional condition is associated with the method area: If memory in the method area cannot be made available to satisfy an allocation request, the Java Virtual Machine throws an OutOfMemoryError. 翻译过来就是： Java虚拟机有一个在所有Java虚拟机线程之间共享的方法区域。方法区类似于常规语言编译代码的存储区，或类似于操作系统进程中的“文本”段。它存储每个类的结构，如运行时常量池、字段和方法数据，以及方法和构造函数的代码，包括类和实例初始化以及接口初始化中使用的特殊方法。 方法区域是在虚拟机启动时创建的。尽管方法区域在逻辑上是堆的一部分，但简单的实现可能选择不进行垃圾收集或压缩。此规范不要求方法区域的位置或用于管理已编译代码的策略。方法区域可以是固定大小的，或者可以根据计算的需要进行扩展，并且可以在不需要更大的方法区域时收缩。方法区域的内存不需要是连续的。 Java虚拟机实现可以提供程序员或用户对方法区域的初始大小的控制，以及在大小不同的方法区域的情况下，控制最大和最小方法区域大小。 以下异常情况与方法区域有关： 如果方法区域中的内存无法用于满足分配请求，Java虚拟机将抛出OutOfMemoryError。 总结：方法区是运行时数据区中的公共部分，生命周期与虚拟机绑定，所有线程可共享。其实方法区只是一个逻辑概念，本质上方法区就是堆的一部分。但是因为方法区存储的通常都是常量、字段、方法数据、代码文本等，所以可以不进行垃圾回收，故Java虚拟机规范单独把方法区拆出来作为运行时数据区的一部分。方法区的内存不需要是连续的，方法区的大小也可以由用户自行设定。 5. 运行时常量池（Run-Time Constant Pool）官方文档： A run-time constant pool is a per-class or per-interface run-time representation of the constant_pool table in a class file (§4.4). It contains several kinds of constants, ranging from numeric literals known at compile-time to method and field references that must be resolved at run-time. The run-time constant pool serves a function similar to that of a symbol table for a conventional programming language, although it contains a wider range of data than a typical symbol table. Each run-time constant pool is allocated from the Java Virtual Machine’s method area (§2.5.4). The run-time constant pool for a class or interface is constructed when the class or interface is created (§5.3) by the Java Virtual Machine. The following exceptional condition is associated with the construction of the run-time constant pool for a class or interface: When creating a class or interface, if the construction of the run-time constant pool requires more memory than can be made available in the method area of the Java Virtual Machine, the Java Virtual Machine throws an OutOfMemoryError. See §5 (Loading, Linking, and Initializing) for information about the construction of the run-time constant pool. 翻译过来就是： 运行时常量池是类文件中常量池表的每个类或每个接口的运行时表示。它包含几种常量，从编译时已知的数字字面值到必须在运行时解析的方法和字段引用。运行时常量池的功能类似于传统编程语言的符号表，尽管它包含的数据范围比典型的符号表更广。 每个运行时常量池都是从Java虚拟机的方法区域分配的。类或接口的运行时常量池是在Java虚拟机创建类或接口时构造的。 以下异常情况与类或接口的运行时常量池的构造相关： 在创建类或接口时，如果构建运行时常量池所需的内存超过了Java虚拟机的方法区域中可用的内存，则Java虚拟机将抛出OutOfMemoryError。 总结：运行时常量池属于方法区，方法区数据堆，所以运行时常量池同方法区一样，也是一个逻辑概念，同样也是运行时数据区中的公共部分，与虚拟机生命周期绑定，所有线程共享。 6. 本地方法栈（Native Method Stacks）官方文档： An implementation of the Java Virtual Machine may use conventional stacks, colloquially called “C stacks,” to support native methods (methods written in a language other than the Java programming language). Native method stacks may also be used by the implementation of an interpreter for the Java Virtual Machine’s instruction set in a language such as C. Java Virtual Machine implementations that cannot load native methods and that do not themselves rely on conventional stacks need not supply native method stacks. If supplied, native method stacks are typically allocated per thread when each thread is created. This specification permits native method stacks either to be of a fixed size or to dynamically expand and contract as required by the computation. If the native method stacks are of a fixed size, the size of each native method stack may be chosen independently when that stack is created. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the native method stacks, as well as, in the case of varying-size native method stacks, control over the maximum and minimum method stack sizes. The following exceptional conditions are associated with native method stacks: If the computation in a thread requires a larger native method stack than is permitted, the Java Virtual Machine throws a StackOverflowError. If native method stacks can be dynamically expanded and native method stack expansion is attempted but insufficient memory can be made available, or if insufficient memory can be made available to create the initial native method stack for a new thread, the Java Virtual Machine throws an OutOfMemoryError. 翻译过来就是： Java虚拟机的实现可以使用传统的堆栈（俗称“C堆栈”）来支持Native方法（用Java编程语言以外的语言编写的方法）。Native方法栈也可用于实现Java虚拟机指令集的解释器，如C语言。不能加载本机方法且本身不依赖传统堆栈的Java虚拟机实现不需要提供本机方法栈。如果提供了本机方法堆栈，则通常在创建每个线程时为每个线程分配。 此规范允许本机方法堆栈可以是固定大小的，也可以根据计算的需要动态扩展和收缩。如果本机方法堆栈的大小是固定的，则在创建该堆栈时，可以独立选择每个本机方法堆栈的大小。 Java虚拟机实现可以为程序员或用户提供对本机方法堆栈初始大小的控制，以及在大小不同的本机方法堆栈的情况下，控制最大和最小方法堆栈大小。 以下异常情况与本机方法堆栈相关： 如果线程中的计算需要比允许的更大的本机方法堆栈，Java虚拟机将抛出StackOverflowError。 如果可以动态扩展本机方法堆栈并尝试扩展本机方法堆栈，但可用内存不足，或者如果可用内存不足，无法为新线程创建初始本机方法堆栈，则Java虚拟机将抛出OutOfMemoryError。 总结：本地方法栈是用来支持native方法的，本地方法栈不是每个JVM实现所必须的（如果你设计的这个JVM实现根本就不需要执行native方法，那你就根本没必要设计这个本地方法栈），如果需要设计本地方法栈，则需要和线程生命周期绑定。这个本地方法栈是每个线程独享的，属于运行时数据区中非公共部分。 根据官方虚拟机规范文档，可以得出运行时数据区的逻辑关系如下： 补充： 实际上Hotspot虚拟机并没有区分Java虚拟机栈和本地方法栈，直接通用了。 三、运行时数据区在Java6/7/8中的对比 在Java6的运行时数据区中，运行时常量池–（属于）-&gt; 方法区 –(属于)–&gt; 堆 ， 按照堆内存的分代划分，方法区属于永久代。直接内存用于NIO。Java堆用于存放对象的实例。而方法区存放类信息、运行时常量池、静态变量、字符串常量池。 在Java7的运行时数据区中，运行时常量池–（属于）-&gt; 方法区 –(属于)–&gt; 堆 ， 按照堆内存的分代划分，方法区属于永久代。直接内存用于NIO。Java堆用于存放对象的实例、静态变量、字符串常量池。而方法区存放类信息、运行时常量池。 在Java8的运行时数据区中，方法区直接放到了本地内存中的元空间中（Java8取消了永久代，新增了元空间，元空间直接放在本地内存中的）。所以此时本地内分为NIO所使用的直接内存和元空间。Java堆用于存放对象的实例、静态变量、字符串常量池。而方法区存放类信息、运行时常量池。 以上图片来自于网络","categories":[{"name":"Java","slug":"Java","permalink":"https://sombreknight.gitee.io/categories/Java/"},{"name":"虚拟机","slug":"Java/虚拟机","permalink":"https://sombreknight.gitee.io/categories/Java/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://sombreknight.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://sombreknight.gitee.io/tags/JVM/"}]},{"title":"《中间件之Redis》系列一：基础总结","slug":"TvwqUdDOBHHrMjB3","date":"2021-01-23T15:30:17.000Z","updated":"2021-01-23T15:29:34.000Z","comments":true,"path":"2021/01/23/TvwqUdDOBHHrMjB3/","link":"","permalink":"https://sombreknight.gitee.io/2021/01/23/TvwqUdDOBHHrMjB3/","excerpt":"","text":"​ 在这一篇中，我将对Redis的基础使用进行一个全方位的总结。 总结的内容如下： 5种基础数据结构 字符串-string 列表-list 字典-hash 集合-set 有序集合-zset 容器型数据结构的通用规则 过期时间 管道 事务 缓存穿透/击穿/雪崩 一、5种基础数据结构1. 字符串-string字符串是Redis最简单的数据结构。需要记住以下两点： redis中的字符串是一种可变字符串，内部实现了类似于Java ArrayList的动态扩容机制，当字符串长度小于1MB时，扩容都是直接加倍现有的框架；当字符串长度超过1MB时，扩容一次只会多扩1MB。 字符串的最大长度时512MB 基本操作如下： 简单键值对读写 12345678910&gt; set name zhangchenxiOK&gt; get name&quot;zhangchenxi&quot;&gt; del name(integer) 1&gt; get name(nil)&gt; exists name(integer) 0 批量键值对读写 1234567891011121314&gt; set name1 zhangsanOK&gt; set name2 lisiOK&gt; mget name1 name2 name31) &quot;zhangsan&quot;2) &quot;lisi&quot;3) (nil)&gt; mset name1 z3 name2 l4 name3 w5OK&gt; mget name1 name2 name31) &quot;z3&quot;2) &quot;l4&quot;3) &quot;w5&quot; 过期 123456789&gt; set name zhangchenxiOK&gt; expire name 5 # 设置5s后过期(integer) 1&gt; get name &quot;zhangchenxi&quot;# ...5s后...&gt; get name (nil) set命令扩展 1234567&gt; setex name 5 zhangchenxi # setex 等价于 set + expireOK&gt; get name&quot;zhangchenxi&quot;# ...5s后...&gt; get name(nil) 12345678&gt; setnx name zhangchenxi # 当name这个key没有对应的value时，才能set成功(integer) 1&gt; get name&quot;zhangchenxi&quot;&gt; setnx name zhangsan(integer) 0&gt; get name&quot;zhangchenxi&quot; 计数 123456789101112131415161718192021222324252627&gt; set age 10 # 只有当value为整数时，才能使用incr和incrbyOK&gt; incr age(integer) 11&gt; incr age(integer) 12&gt; incr age(integer) 13&gt; incrby age 2(integer) 15&gt; incrby age 2(integer) 17&gt; incrby age -2(integer) 15&gt; incrby age -2(integer) 13# -----错误示例-----&gt; set age hahaOK&gt; incr age(error) ERR value is not an integer or out of range&gt; incrby age 2(error) ERR value is not an integer or out of range&gt; set age 11.1OK&gt; incr age(error) ERR value is not an integer or out of range 2. 列表-list Redis中的list相当于Java语言里面的LinkedList（实际上底层用了一个QuickList的结构，后续对数据结构源码实现总结时再梳理，这里可以先简单理解为LinkedList），注意它是链表而不是数组。这意味着list的插入和删除操作非常快，时间复杂度为O(1)，但是索引定位很慢，时间复杂度为O(n)。Redis中的list是个双向链表，每个元素都使用双向指针串联，支持前向后向遍历。 作为队列来使用 123456789101112131415161718192021&gt; rpush queue 1 2 3 (integer) 3&gt; rpush queue 4(integer) 4&gt; lrange queue 0 -1 # lrange会遍历链表，时间复杂度O(n),在实际开发中要慎用1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;&gt; lpop queue # O(1)&quot;1&quot;&gt; lpop queue&quot;2&quot;&gt; lpop queue&quot;3&quot;&gt; lpop queue&quot;4&quot;&gt; lpop queue(nil)&gt; lrange queue 0 -1(empty list or set) 作为栈来使用 123456789101112131415161718192021&gt; rpush stack a b c (integer) 3&gt; rpush stack d(integer) 4&gt; lrange stack 0 -1 # lrange会遍历链表，时间复杂度O(n),在实际开发中要慎用1) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot;4) &quot;d&quot;&gt; rpop stack # O(1)&quot;d&quot;&gt; rpop stack&quot;c&quot;&gt; rpop stack&quot;b&quot;&gt; rpop stack&quot;a&quot;&gt; rpop stack(nil)&gt; lrange stack 0 -1(empty list or set) list的慢操作 1234567891011121314151617181920&gt; rpush queue a b c d(integer) 4&gt; lindex queue 1 # lindex操作相当于Java链表中的get(int index)方法，时间复杂度O(n),实际开发中慎用&quot;b&quot;&gt; lrange queue 0 -1 # lrange操作复杂度O(n)，实际开发中慎用1) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot;4) &quot;d&quot;&gt; ltrim queue 1 2 # ltrim操作，将start,stop索引之外的元素都删除，复杂度O(n)，实际开发中慎用OK&gt; lrange queue 0 -11) &quot;b&quot;2) &quot;c&quot;&gt; llen queue # 这个写在这儿是为了和lrange区分，llen是正儿八经的O(1)复杂度，实际开发中放心使用(integer 2)&gt; ltrim queue 1 0 # 利用ltrim清空list，[1,0]是个负区间，将直接清空ltrim，没啥意义的骚操作，实际开发中千万不能这么玩儿OK&gt; lrange queue 0 -1(empty list or set) 作为异步队列使用 作为异步队列使用的原理大概是：将需要异步处理的任务序列化后存如list，然后在另一个线程对这个列表进行轮询数据处理。 作为异步队列使用，将放在后面的Redis应用系列文章中总结，这里不再赘述。 3. 字典-hashRedis中的字典-Hash结构相当于Java中的HashMap，都是数组+链表的二维结构实现方式。当第一维hash的数组位置碰撞时就会将碰撞元素使用链表串起来。但是和Java的HashMap不同的是：Redis为了追求高性能，使用了渐进式rehash，关于redis的hash结构rehash过程，在后续的深入原理文章中再梳理总结。 注意：Redis中Hash结构的value，只能存放字符串 基本操作 123456789101112131415161718192021222324252627282930&gt; hset person name zhangsan(integer) 1&gt; hset person age 18(integer) 1&gt; hset person addr beijing(integer) 1&gt; hgetall person1) &quot;name&quot;2) &quot;zhangsan&quot;3) &quot;age&quot;4) &quot;18&quot;5) &quot;addr&quot;6) &quot;beijing&quot;&gt; hlen person(integer) 3&gt; hget person name&quot;zhangsan&quot;&gt; hset person name lisi(integer) 0&gt; hget person name&quot;lisi&quot;&gt; hmset person name zhang3 age 20 addr chengduOK&gt; hgetall person1) &quot;name&quot;2) &quot;zhang3&quot;3) &quot;age&quot;4) &quot;20&quot;5) &quot;addr&quot;6) &quot;chengdu&quot; 计数操作 1234567891011121314151617&gt; hgetall person1) &quot;name&quot;2) &quot;zhang3&quot;3) &quot;age&quot;4) &quot;20&quot;5) &quot;addr&quot;6) &quot;chengdu&quot;&gt; hget person age&quot;20&quot;&gt; HINCRBY person age 1(integer) 21&gt; HINCRBY person age 1(integer) 22&gt; HINCRBY person age -1(integer) 21&gt; HINCRBY person age -1(integer) 20 4. 集合-set ​ Redis的集合相当于Java的HashSet，内部的键值对是无序的、唯一的。它的内部实现相当于一个特殊的字典（Hash），不过所有的value都是NULL。 基本操作 12345678910111213141516171819202122232425262728293031323334&gt; sadd books python(integer) 1&gt; sadd books python # set中已有了，所以返回0(integer) 0&gt; sadd books java(integer) 1&gt; sadd books golang(integer) 1&gt; smembers books # 查询集合的全部元素，顺序和sadd的顺序不一致1) &quot;java&quot;2) &quot;python&quot;3) &quot;golang&quot;&gt; sismember books java # 判断集合中是否存在某个元素，存在返回1，否则返回0(integer) 1&gt; sismember books php(integer) 0&gt; scard books # 获取集合的长度(integer) 3&gt; spop books # 从集合中“随机”弹出一个元素&quot;golang&quot;&gt; scard books(integer) 2&gt; spop books&quot;java&quot;&gt; scard books(integer) 1&gt; spop books&quot;python&quot;&gt; scard books(integer) 0&gt; spop books(nil)&gt; scard books(integer) 0 5. 有序集合-zsetzset是Redis中最具特色的数据结构。一方面它是一个set，保证了内部value的唯一性，另一方面它可以给每个value赋予一个score，表示value的排序权重。它的内部实现用的是一种叫做“跳跃列表”的数据结构。 基础用法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&gt; zadd language 9.0 java(integer) 1&gt; zadd language 8.9 python(integer) 1&gt; zadd language 8.8 php(integer) 1&gt; zadd language 8.5 c(integer) 1&gt; zadd language 8.4 c++(integer) 1&gt; zadd language 8.2 javaScript(integer) 1&gt; zrange language 0 -1 # 按score排升序列出，参数区间为排名范围，当区间为负，则全排名输出1) &quot;javaScript&quot;2) &quot;c++&quot;3) &quot;c&quot;4) &quot;php&quot;5) &quot;python&quot;6) &quot;java&quot;&gt; zrange language 0 2 # 按score排升序，取出前三名1) &quot;javaScript&quot;2) &quot;c++&quot;3) &quot;c&quot;&gt; zrevrange language 0 -1 # 按score将序列出，当区间为负，全排名输出1) &quot;java&quot;2) &quot;python&quot;3) &quot;php&quot;4) &quot;c&quot;5) &quot;c++&quot;6) &quot;javaScript&quot;&gt; zrevrange language 0 2 # 按score将序列出，输出前3名1) &quot;java&quot;2) &quot;python&quot;3) &quot;php&quot;# ----------------------------------------------------------------------------&gt; zcard language # 获取zset的长度(integer) 6&gt; zscore language java # 获取指定value的score，内部score使用double类型存储，所以存在小数点精度问题&quot;9&quot;&gt; zscore language python&quot;8.9000000000000004&quot;&gt; zscore language php&quot;8.8000000000000007&quot;&gt; zscore language javaScript&quot;8.1999999999999993&quot;&gt; zrank language java # 按照score升序排序，获取Java的排名索引(integer) 5&gt; zrank language javaScript # 按照score升序排序，获取javaScript的排名索引(integer) 0&gt; zrangebyscore language 8.1 8.5 # 输出[8.1,8.5]区间的升序排名1) &quot;javaScript&quot;2) &quot;c++&quot;3) &quot;c&quot;127.0.0.1:6379&gt; zrangebyscore language 8.1 8.5 withscores # 输出[8.1,8.5]区间的升序排名，并且输出score1) &quot;javaScript&quot;2) &quot;8.1999999999999993&quot;3) &quot;c++&quot;4) &quot;8.4000000000000004&quot;5) &quot;c&quot;6) &quot;8.5&quot;&gt; zrangebyscore language -inf 8.5 # -inf表示负无穷1) &quot;javaScript&quot;2) &quot;c++&quot;3) &quot;c&quot;&gt; zrangebyscore language -inf 8.5 withscores1) &quot;javaScript&quot;2) &quot;8.1999999999999993&quot;3) &quot;c++&quot;4) &quot;8.4000000000000004&quot;5) &quot;c&quot;6) &quot;8.5&quot;&gt; zrem language c # 从zset中删除某个value(integer) 1 二、容器型数据结构的通用规则 List、Set、Hash、Zset这四种数据结构是容器型数据结构。 它们都有下面两条通用规则： create if not exists: 如果容器不存在，就创建一个再进行操作； drop if no elements: 如果容器内没有元素了，就删除此容器。 三、过期时间​ Redis所有的数据结构都可以设置过期时间，时间到了，Redis会自动删除相应的对象。需要注意的是，过期是以对象为单位的。比如一个hash结构的过期是整个hash对象过期，而不是其中某个key过期。 另外，如果一个对象已经设置了过期时间，如果对其重新进行了写入操作，过期时间会失效。 12345678910&gt; set name zhangchenxiOK&gt; expire name 10(integer) 1&gt; ttl name(integer) 8&gt; set name aaaOK&gt; ttl name(integer) -1 关于“过期”这个话题，还不得不提到Redis的过期失效策略。这篇文章不详细写了，后续深入Redis底层实现原理的文章再具体梳理总结下。 四、管道​ 管道（Pipedline）本身并不是Redis服务器直接提供的技术，这个技术本质上是由客户端提供的，跟服务器没有什么直接的关系。客户端通过对管道中的指令列表改变读写顺序就可以大幅节省IO时间。 如上图所示，正常情况下，redis客户端每次请求服务的执行一个指令都要经过一次写&amp;读，如果执行指令越多，读写IO的次数就越多。现在客户端通过管道，对要执行的指令进行重新排序，将多次写和多次读放在一次IO中，这样就大大减少了IO的次数。 压力测试一下，不使用管道和使用管道后的QPS： 123456789101112131415161718192021222324252627282930313233zhangchenxi➜~» redis-benchmark -t set -q # 不使用管道，正常情况下测set指令的QPS [23:19:57]SET: 140646.97 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 2 -q # 使用管道，管道内并行请求数量为2时，set的qps约为27w [23:20:11]SET: 268817.19 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 3 -q [23:20:29]SET: 384615.41 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 4 -q [23:20:37]SET: 490196.09 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 5 -q [23:20:40]SET: 540540.56 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 6 -q [23:20:44]SET: 595238.12 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 7 -q [23:20:47]SET: 613496.94 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 8 -q [23:20:50]SET: 653594.81 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 9 -q [23:20:52]SET: 666666.62 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 10 -q # 管道内并行请求达到10时，QPS可以达到70W+ [23:20:56]SET: 704225.31 requests per secondzhangchenxi➜~» redis-benchmark -t set -P 11 -q [23:20:58]SET: 689655.19 requests per second 压力测试对比，在我的机器上，对一个普通set压测，QPS大概在14w/s, 当使用管道后，管道内的请求数量达到10左右时接近峰值在70W/s左右，再往后QPS不再增加了，因为已经达到了CPU的极限了。由此可见，管道对QPS的提升作用是非常明显且巨大的。 五、事务Redis的事务非常简单，但是其事务模型也非常不严格。我们不能像使用关系型数据库的事务一样来使用Redis事务。 Redis事务特点如下： 不是原子性的，某一步失败了，后续的操作还会执行，Redis事务仅仅满足了事务隔离性中的串行化——当前事务有着不被其他事务打断的权利 Redis事务不支持回滚 基本示例 1234567891011121314151617181920212223127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set hot 18 # 将指令加入事务队列了，这个过程会有IO操作QUEUED127.0.0.1:6379&gt; incr hotQUEUED127.0.0.1:6379&gt; incr hotQUEUED127.0.0.1:6379&gt; set test abQUEUED127.0.0.1:6379&gt; incr test # 这里故意让此命令报错，验证Redis事务的原子性QUEUED127.0.0.1:6379&gt; exec # 提交后事务队列中的指令一条条的被执行1) OK2) (integer) 193) (integer) 204) OK5) (error) ERR value is not an integer or out of range # 这里可以看到，确实incr test执行失败了127.0.0.1:6379&gt; get hot # 发现执行成功了，说明redis事务不具备原子性&quot;20&quot;127.0.0.1:6379&gt; get test # 发现执行成功了，说明redis事务不具备原子性&quot;ab&quot;127.0.0.1:6379&gt; 丢弃事务 123456789127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set book javaeeeQUEUED127.0.0.1:6379&gt; discardOK127.0.0.1:6379&gt; get book(nil)127.0.0.1:6379&gt; 利用pipline可以优化加入事务队列中的IO过程，提示效率，以python代码为例 12345pipe = redis.pipline(transaction=True)pipe.multi()pipe.incr(&quot;books&quot;)pipe.incr(&quot;books&quot;)values = pipe.execute() 利用watch实现一个乐观锁事务，watch的变量如果在事务执行前修改了，事务会整体失败。（注意：Redis禁止在multi和exec之间执行watch指令，必须在multi之前盯住关键变量，否则报错） 123456789101112127.0.0.1:6379&gt; watch books # watch指令盯住books变量，如果在事务exec之前，变量发生了变化，则事务会执行失败，返回nilOK127.0.0.1:6379&gt; incr books # 在事务执行前悄悄改了book变量的值(integer) 1127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; incr booksQUEUED127.0.0.1:6379&gt; exec # 执行事务，果然失败了(nil)127.0.0.1:6379&gt; get books # 获取值，还是原来的值，事务没有执行成功&quot;1&quot; 六、缓存穿透/击穿/雪崩 如上图总结所示： &gt; 缓存穿透 &lt;解释： 请求到缓存，没有查到数据，又去查数据库了，但是数据库里也没查到，返回后在缓存中依然没有缓存，下一次相同的查询进来仍然会查询数据库，这样就造成了缓存击穿。 解决方案： 数据库查询后，即使没有查询出结果，也可以返回一个空值，下次请求就可以直接命中缓存了； 使用布隆过滤器，先确认下数据是否不存在，避免对redis和数据库的查询 &gt; 缓存击穿 &lt;解释： 请求到缓存，没有查到数据，又去查数据库了，数据库中查到了，但是在数据库查询结果回写到缓存之前，还有大量查询命中到了数据库上，就造成了缓存击穿。 解决方案： 加锁，避免大量请求访问数据库； 不允许过期，在逻辑上异步更新数据； 采用二级缓存，L1失效时间短，L2失效时间长。请求优先从L1缓存查询数据，如果未命中，则加锁，保证只有一个线程去数据库中查询数据并更新L1和L2缓存。加锁过程中其他线程可以从L2缓存获取数据。 &gt; 缓存雪崩 &lt;解释：大量key同一时刻失效，使得同一时刻的大量请求都命中到数据库上了，由此造成缓存雪崩。 解决方案： 对Key设置不同的失效时间，避免大量key同时失效； 缓存预热。在系统启动时，现将数据加入到缓存中预热，保证数据在使用之前缓存中已经有了； 通过加锁的方式来限流，减轻数据库压力。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://sombreknight.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"系列文章","slug":"中间件/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://sombreknight.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"Redis","permalink":"https://sombreknight.gitee.io/tags/Redis/"}]},{"title":"《中间件之Redis》系列：概览","slug":"kaVJkC1gBmnwKAty","date":"2021-01-18T01:52:04.000Z","updated":"2021-01-18T01:51:35.000Z","comments":true,"path":"2021/01/18/kaVJkC1gBmnwKAty/","link":"","permalink":"https://sombreknight.gitee.io/2021/01/18/kaVJkC1gBmnwKAty/","excerpt":"","text":"​ Redis在我们的日常开发中，可以说“太重要了”。其在诸多场景下发挥着不同的作用。在这个系列中，我想将自己对于Redis的学习使用做一个大的总结。 我将从以下几个方面对Redis进行一个较为全方位的总结： Redis基本数据结构、使用方式以及复杂度 基础数据结构、命令、复杂度 缓存击穿 缓存穿透 缓存雪崩 基于Redis的常见应用 分布式锁 &amp; RedLock 限流器 消息队列 布隆过滤器 Redis的持久化 快照 AOF Redis的高可用 主从 哨兵 集群 Redis的线程IO模型 更深入的一些知识… 这篇文章将作为Redis系列文章的一个“目录”角色，方便将来速查Redis的相关知识总结。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://sombreknight.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"系列文章","slug":"中间件/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://sombreknight.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"Redis","permalink":"https://sombreknight.gitee.io/tags/Redis/"}]},{"title":"《高并发红包炸弹项目性能优化》系列三：接口性能优化","slug":"N2ci7yWyasJw5Jbu","date":"2021-01-15T12:27:03.000Z","updated":"2021-01-15T12:26:45.000Z","comments":true,"path":"2021/01/15/N2ci7yWyasJw5Jbu/","link":"","permalink":"https://sombreknight.gitee.io/2021/01/15/N2ci7yWyasJw5Jbu/","excerpt":"","text":"一、开始​ 在上一篇文章《高并发红包炸弹项目性能优化》系列二：方案设计 中，我具体介绍了下该红包炸弹需求的实现方案，包括数据库表的设计、前端的限流请求措施、服务端关键接口的代码实现。在这一篇博客中，我将从服务端接口代码优化开始，逐步展开对整个红包炸弹项目的优化历程。毕竟，最重要的还是核心的业务接口。接口写得性能够好了，就成功一半了。剩下的无非是采取一些常见的手段，进行二次优化而已。真正需要动刀子的，还是在业务接口上。 二、接口优化原则​ 面对接口的性能优化，我这样思考： ​ 接口，做了什么事？无非就是读/写。所有的网络请求都是在读/写。那优化的最终目标是什么？ ​ 答案就是：让单位时间能够支持“更多”的读/写请求！ ​ 剩下的问题就很简单了，我们采取各个击破的办法。 如何让读取更快 如何让写入更快 接下来就这两点，我来谈谈自己的处理意见。 1. 如何让读取更快 减少DB查询，能走缓存就一定要走缓存；特殊业务场景要，可以在硬件上加大投入，给Redis集群进行扩容什么的都是OK的； 既然要走缓存，一定要考虑到数据一致性、缓存穿透、缓存击穿、缓存雪崩这三个问题，既然要用缓存就一定要用好缓存； 实在要走库的查询，一定要注意查询性能。主要从以下两方面优化： 建立好自己的业务数据表模型，该垂直拆表的地方就拆，该冗余字段的地方就冗余，尽量保证自己的业务接口使用简单SQL查询。当然不管拆表还是冗余都是有代价的，可能需要维护数据的一致性，可能需要开事务进行多表写入。具体问题具体分析。 一旦数据表一定，很难再做修改的情况下，那就要更多地在SQL优化上下功夫。一般建议SQL查询计划至少要达到ref级别，能到const级别那当然更好； 2. 如何让写入更快 写入的话，能写缓存，当然不建议写库。但是对于缓存，要考虑的问题更多，选用哪种数据结构，怎样保证数据一致性，什么时候缓存落库，缓存淘汰策略是什么，还有不要造成大面积缓存失效导致的缓存雪崩; 直接写库的话，要考虑下是否要优化表结构，尽可能在设计的时候就考虑减少锁冲突，表设计时还可以考虑使用乐观锁，能不用事务就不用事务，可以考虑定时任务来兜底，也可以考虑走MQ进行异步写库； 要考虑数据所使用的事务隔离级别，隔离级别越高，并发性越低；如果根本不存在事务问题，不使用带事务支持的数据库引擎也OK； 三、高并发下还需要考虑哪些优化 如果用到了分布式锁，一定要保证锁的及时释放，锁不及时释放，反而可能导致接口的吞吐量降低；另外就是分布式锁的选型，一般有基于Redis、Zookeeper以及数据库实现这三种，一般来说Redis锁更适合高并发下使用，Redis实现分布式锁相对于ZK和数据库来说也更简单； 还需要再提下分布式锁的使用，在高并发下不推荐使用带有超时退出的自旋锁，因为线程自旋会加大CPU的使用负担，同时也会持续占用线程，如果有大量的线程自旋，会导致把机器上的最大线程数打满（这个机器的线程数在Linux上是可以配置的，但仍然有上线），如此一来服务就不能分配出可用的线程继续提供服务了，会直接导致高并发下接口的吞吐量降低； 线程池技术的使用。要注意线程池的参数配置、以及阻塞队列是否有界、容量最大为多少，避免高并发下造成OOM，另外还需要注意使用线程池时线程复用下会不会有内存泄漏的问题，在合理的节点进行内存释放； 接口限流。在不考虑实际业务场景时，限流根本目的就是就是为了保护DB，因为在大多数情况下，DB是公共资源，不能因为一个业务，就把整个公共资源搞挂吧； 优化代码逻辑。所谓条条大路通罗马，但是通往罗马所付出的代价却是不一样的。简单的说就是用更好的算法处理业务逻辑。更好的算法往往可以更快的处理完业务逻辑，占用更小的空间，更少的IO次数。面对高并发，我们有必要绞尽脑汁去思考更聪明的做法。 OK，至此，我总结了一些自己对于优化接口性能这件事上的一些宏观上的认识。当然性能优化可以从各个角度入手，远远不止我提到的这些。对于性能优化，我们应该采用贪心算法的思想，在各个环节优化到最好，最后的整体性能一定不会低到哪儿去。接下来，我们就正式开始进行红包炸弹项目的关键接口性能优化工作。 四、简单优化创建红包接口​ 在《高并发红包炸弹项目性能优化》系列二：方案设计 我贴上了项目交接前红包炸弹的具体创建接口的实现代码。 这里我再次把红包炸弹的创建逻辑再次说明下，如下图中的表结构所示，创建红包炸弹其实就是在红包表中新增一条红包记录，以及新增与此红包记录所关联的”若干”条子红包记录。这里的“若干”就是红包表中的num字段所指定的数量。 图1-红包炸弹的表设计 这里再补充一下需求，产品认为同一时间只能有一个正在进行中的红包。也就是说，如果在创建红包时还有处于未开抢的，或者正在被抢的红包，或者还没有置完成的红包，那么这时不能投放新的红包的。另外，投放红包只有管理员才可以进行操作。因为对于此接口我们并没有太多的并发度要求。我只要保证此接口可以逻辑正确、可靠的执行完成就OK了。 图2-创建红包接口的优化前后diff截图 如上图2所示，是对创建接口的一些基本优化后的前后diff截图。 在创建接口的入口处，添加了一处判断逻辑： 12345//爆炸时间必须至少在当前时间的1分钟后,这样才能做到爆炸前60s通知IM if (!startTime.after(new HaoDate().offsetMinutes(1)))&#123; return RpcResponse.error(ErrorCode.RED_ENVELOPE_TIME_ERROR); &#125; ​ 为什么加这么一个判断呢，因为按照需求，我们需要在爆炸前60s发送一个IM消息，通知前端开始进行红包炸弹的一分钟倒计时。如果在创建红包时所指定的红包炸弹炸开时间在将来的不到一分钟内。那么我们无法就无法满足需求了。即红包一创建，里炸开时间就已经小于60秒了，这种情况下进行红包60秒倒计时显然是不合适的。 优化锁使用，这里应该明显是应该先获取锁，再判断是否还有进行中的红包。使用try…finally…保证锁最终会被释放。 12345678910111213HdfAssert.isTrue(redisLocker.lock(redisLock),ErrorCode.ACTION_FAST);try &#123; if (redEnvelopeLogic.isExistDoingRedEnvelope())&#123; return RpcResponse.error(ErrorCode.EXIST_DOING_RED_ENVELOPE); &#125; redEnvelopeLogic.create(num, price, inspectId, TYPE_AUDITOR, startTime); redEnvelopeLogic.sendNoticeToIM(redEnvelopeDAO.queryLatestRedEnvelope(), CelebrationConstants.Hdf_Celebration_Bomb);&#125;finally &#123; redisLocker.unlock(redisLock);&#125;return RpcResponse.success(&quot;创建成功&quot;); 另外这里，为了防止MySQL的主从延迟导致调用上面的第3行redEnvelopeLogic.isExistDoingRedEnvelope()这个方法得到错误的结果，对于此查询强制走主库。 深入优化创建红包逻辑，如下图3所示 图3-创建红包的核心逻辑修改后的diff 这里改动逻辑是： 创建红包记录，要关注其返回值，确认创建成功了，才继续进行后续的创建子红包任务、创建自动完成延迟任务、创建倒计时延迟任务； 创建红包成功后，这里将红包id缓存了一份在Redis中。用于记录最新的正在进行中的红包id。这里缓存此id其实是为了后续优化用户端调用的接口查询，将在后续讲解到解决IM推送不及时的问题时提到其用途； 红包炸开后15秒自动完成以及红包炸开前1分钟倒计时，原本是使用延迟MQ实现，这里改使用ScheduledThreadPoolExecutor实现了。因为这个延迟MQ需要随机计算出一个从创建红包的时刻到目标时刻的延迟时间，每次创建都有可能产生一个延迟MQ队列，受限于公司的MQ架构延迟队列数量限制，此方法不可取。所以这里使用了ScheduledThreadPoolExecutor来实现。 具体封装如下： 123456789101112131415161718192021222324@Componentpublic class ScheduledThreadPool &#123; private ScheduledThreadPoolExecutor scheduledThreadPoolExecutor; @PostConstruct public void init() &#123; int coreSize = Runtime.getRuntime().availableProcessors(); scheduledThreadPoolExecutor = new ScheduledThreadPoolExecutor(coreSize , Executors.defaultThreadFactory() , new ThreadPoolExecutor.CallerRunsPolicy()); &#125; /** * 延迟调用 * * @param runnable runnable * @param time 秒数 */ public void delayCall(Runnable runnable, long time) &#123; scheduledThreadPoolExecutor.schedule(runnable, time, TimeUnit.SECONDS); &#125; @PreDestroy public void destroy()&#123; scheduledThreadPoolExecutor.shutdown(); &#125;&#125; 因为在这个业务可以提前确认只会有1分钟倒计时和15秒自动完成这两个延迟任务，所以对于这个ScheduledThreadPoolExecutor的参数配置，并无太多考究。可以用即可。 但是ScheduledThreadPoolExecutor也存在一个严重的问题，那就是这不是一个分布式的调度器，也不具备持久化任务的能力，所以在服务重启等特殊情况下，延迟任务可能丢失。具体使用一定要看场景。 比如，在红包炸弹里，15s自动完成的延迟任务是这样使用ScheduledThreadPoolExecutor的： 123456789101112131415161718192021222324252627282930313233private void setAutoComplete(RedEnvelopeDO redEnvelopeDO) &#123; long now = HaoDate.currentTimeSecond(); long delay = redEnvelopeDO.getTime().getTimeSecond() - now + Long.parseLong(cloudCountDown) + 5; if (delay &lt;= 0) &#123; delay = 0; &#125; RedEnvelopeMessage msg = new RedEnvelopeMessage(); msg.setRedEnvelopeId(redEnvelopeDO.getId()); //存redis标记，表示又一个异步任务待执行 redisClient.set(REDIS_KEY_TASK_WAITING_AUTO_COMPLETE_FLAG, redEnvelopeDO.getId().toString()); scheduledThreadPool.delayCall(() -&gt; &#123; this.autoComplete(msg); //清redis标记，表示该异步任务执行完成了 redisClient.delete(REDIS_KEY_TASK_WAITING_AUTO_COMPLETE_FLAG); &#125;, delay);&#125; @PostConstructprivate void init()&#123; ... //查询异步任务标记是否存在，存在说明上一次任务没有执行完，bean就被销毁了，重新拉起调度 String redEnvelopeIdStr = redisClient.get(REDIS_KEY_TASK_WAITING_AUTO_COMPLETE_FLAG); if (StringUtils.isNotEmpty(redEnvelopeIdStr) &amp;&amp; NumberUtils.isNumber(redEnvelopeIdStr)) &#123; long redEnvelopeId = Long.parseLong(redEnvelopeIdStr); if (redEnvelopeId &gt; 0) &#123; RedEnvelopeDO redEnvelope = redEnvelopeDAO.findById(redEnvelopeId); if (Objects.nonNull(redEnvelope) &amp;&amp; redEnvelope.getCompleteTime().isZeroTime()) &#123; //需要重新拉起任务 this.setAutoComplete(redEnvelope); &#125; &#125; &#125;&#125; 如代码所示，在将延迟任务丢给ScheduledThreadPoolExecutor前，将红包id缓存到了用于表示未完成的任务标志redis key中，在延迟任务调度完成后，删除缓存key。这样在服务重启后，当bean被初始化时，回调到init方法，此时再次检查redis中是否还有记录有未完成的红包id。有的话，就让他重新进延迟。说到底，这是一个兜底的方案，因为真有高并发的抢红包状况发生的话，一定在红包炸开后很快就被抢完，用户的动作会主动触发置红包完成。 再回到图3中改动后的178行，看下创建子红包的改动： 图4-子红包的创建与子红包缓存 如上图中的diff所示，主要改动的是关注了子红包创建的返回值，只有当子红包创建成功的时候，才会向Redis中维护子红包id的List进行Rpush。可以说这里非常重要，如果无法维护子红包和缓存中的子红包List的数据一致性，则可能出现以下两种情况： 某一子红包写库成功了，但是写入redis的失败了：这种情况还好，因为抢红包不可能抢到没有写入库的子红包，不会出现超抢 某一子红包写库失败了，但是写入redis的成功了：这种情况就会出现问题，因为可能抢到的子红包id，在子红包表中并不存在，如果抢红包的接口逻辑不足够健壮，可能导致用户虚抢一场 最后，可能大家会发现，这里并没有使用事务来批量创建数据。原因是，这里可以不用考虑事务，因为创建丢失某个子红包也无伤大雅，顶多就是用户抢不到这个红包了，可以接受。 五、深入优化抢红包接口在第四节里，我简单介绍了下创建红包的接口做了哪些小优化，因为创建接口并不难，所以对此接口也没有太高的性能要求，只要保证接口是好使的，子红包缓存是可靠的即可。接下来的优化抢红包接口才是重头戏。 图5-创建红包后的存储模型 如上图5所示，在创建红包成功后，数据的存储模型应该是这样的。缓存中既存入了正在进行中的红包id，也存如了子红包的id所组成的List。 所以抢红包要做的事情很简单： 基本的条件校验，不满足则不能抢 尝试从子红包id列表缓存中Lpop一个子红包id出来，如果pop不出来数据了，说明红包被抢完了 Lpop出有效的红包后，更新子红包状态，创建一条红包明细记录 看下整体代码优化Diff如下： 这里具体说下在抢红包接口中都做了哪些优化： 首先是在原来的基础校验逻辑上补充了判断，当红包已经完成后，就直接返回，不需要在走后续的代码逻辑了。这里需要说明的是原来的表结构对于状态位的设计是太合理的。红包的状态目前是需要根据status和complete这两个字段共同判断的，但是由于项目已上线，红包表并非只有红包炸弹这个模块在使用，无法更改了，只好对两个字段都进行考虑了； 然后是对于判断用户是否报名了，原来是直接sql查询报名表。现在在这个applyUserLogic.getApplyUserByUserId(userId)方法上维护了一层缓存，处理逻辑如下： 123456789101112131415161718192021222324public ApplyUserDO getApplyUserByUserId(Long userId) &#123; ApplyUserDO applyUser = null; String redisKey = CELEBRATION + GET_APPLY_USER_BY_USER_ID + userId; String cache = cacheUtil.getCache(redisKey); if (Objects.equals(NULL,cache))&#123; //这里是刻意缓存了NULL，表示不用再次查库了，查库也是null，以防止恶意缓存穿透，从而保护DB return null; &#125; if (StringUtils.isNotEmpty(cache))&#123; applyUser = JsonUtils.toObject(cache, ApplyUserDO.class); &#125; if (Objects.nonNull(applyUser))&#123; return applyUser; &#125; applyUser = applyUserDAO.findApplyUserByUserIdAndStatus(userId, ApplyUserConstants.STATUS_DONE); if (Objects.nonNull(applyUser))&#123; //随机缓存5到10分钟，防止缓存大面积失效导致缓存雪崩 cacheUtil.setCache(redisKey, JsonUtils.toJson(applyUser), (long) RandomUtils.randomInt(MINUTE_5,MINUTE_10)); &#125;else&#123; //如果不存在，缓存一个NULL，防止恶意的缓存穿透 cacheUtil.setCache(redisKey, NULL,(long) RandomUtils.randomInt(MINUTE_5,MINUTE_10)); &#125; return applyUser; &#125; 如上面的代码所示，这里编程式地维护了一层缓存，并且考虑到了缓存穿透和缓存雪崩。另外在新增报名记录、报名状态变更时对缓存进行了失效处理，这里就不贴代码了。 再往后面，原来通过sql查询，分别先后判断了此用户是否已经抢过当前红包了、一天内是否已经成功抢了三次红包。这里优化为一处缓存查询就可以了。如下面的代码所示，getGrabSuccessEnvelopeIds方法的作用就是获取此用户在今天所有抢到的红包id所组成的List。所以可以将代码逻辑优化为先判断是否超过次数，再判断是否已经抢过此红包。将两次sql查询，转换为一次Redis IO。 1234567891011121314151617181920212223List&lt;Long&gt; grabSuccessEnvelopeIds = getGrabSuccessEnvelopeIds(userId); //判断是否超过次数 if (grabSuccessEnvelopeIds.size() &gt;= overLimit)&#123; grabRedEnvelopeInfoVO.setType(OVER_GAIN.getType()); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; //判断是否已经抢过红包，这里不可能进来昨天的红包id，前面就拦截了 if (grabSuccessEnvelopeIds.contains(redEnvelopeId))&#123; grabRedEnvelopeInfoVO.setType(ALREADY_GAIN.getType()); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; /** * 获取今日已抢成功的红包id列表 * @param userId 用户id * @return 已抢成功的红包id列表 */ private List&lt;Long&gt; getGrabSuccessEnvelopeIds(long userId)&#123; String todayDateString = new HaoDate().dateString(); List&lt;String&gt; envelopeIdStrList = redisClient.lrange(ONE_DAY_GRAB + todayDateString + userId, 0, -1); return envelopeIdStrList.stream().map(Long::parseLong).collect(Collectors.toList()); &#125; 需要注意的是，这里没有用HASH来存储此缓存是因为目前公司的框架对于Redis提供的Hash相关的api实在难用之际，还不如使用List来实现。getGrabSuccessEnvelopeIds方法中使用了redis的LRANGE操作，这是一个时间复杂度为O(N)的操作，一般情况要慎用。但是这里这处缓存，我们明确可以知道list最大长度为3。因为一条最多能抢成功三次红包。所以LRANGE的时间复杂度对接口的影响可以忽略。 再往后，我优化了Redis锁的使用。 首先是把原本的tryLock设定的5秒超时时间置0了。之所以这样做是因为，在当前这样的高并发需求下，我们需要接口能够处理更多的请求，但是机器可以开启的线程数是有上限的，所以我们不能让线程在获取分布式锁这件事情上自旋等待超时了，正确的做法应该是拿不到锁就立即返回，把线程资源释放出来给别的请求使用。 然后是调整了锁的位置。原来的锁位置台靠前了。获取锁后，还有各种条件判断，在返回语句中还要释放锁。万一中间某一步有异常抛出，这么操作的无法保证锁真的可以及时释放。分布式锁应该锁住的是最核心的需要处理并发的代码块。 获取到锁后，在原先的实现中会先从redis中弹出子红包id，而后又llen查询了一遍子红包id缓存的List长度，如果为空的就将红包置完成。这里的实现又有两个问题被优化： 尝试LPOP一个子红包id，原逻辑中通过try…catch…来区分是不是取到了非正常的子红包id，如果出现异常，则认为子红包已经抢完了。这里完全不需要这么搞，完全可以避免此处异常的判断。 主动LLEN查看子红包idList的长度，来置红包状态完成。这也是一个不必要且拉低接口性能的操作。首先完全可以由用户在LPOP为空时置完成，其次就又回到了LLEN的时间复杂度问题，List的长度越大，LLEN的性能越低，再List没有取空的时候，做这么多LLEN操作完全是在浪费时间。这一次IO完全是可以省去的。 优化代码如下,只需要一次IO操作进行一个时间复杂度为O(1)的LPOP操作即可： 123456789String redEnvelopeItemIdStr = redisClient.lpop(RED_ENVELOPE_ITEM_KEY + redEnvelopeDO.getId()); //如果不是一个数字，说明取空了，置红包状态即可 if (!NumberUtils.isNumber(redEnvelopeItemIdStr)) &#123; setRedEnvelopeComplete(redEnvelopeId); grabRedEnvelopeInfoVO.setType(NO_GAIN.getType()); //将缓存中记录的正在进行的红包id值清0 redEnvelopeLogic.removeDoingRedEnvelopeIdCache(); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; 再往后这一处优化，我觉得都不能算优化吧。应该是意识问题了，原逻辑这么写的： 12345678910111213141516171819RedEnvelopeItemDO redEnvelopeItemDO = redEnvelopeItemDAO.findById(redEnvelopeItemId);//这里都不需要对redEnvelopeItemDO判个空么？ jdbcDAO.withTransaction(()-&gt;&#123; RedEnvelopeRefDO redEnvelopeRefDO = new RedEnvelopeRefDO(); redEnvelopeRefDO.setPrice(redEnvelopeItemDO.getPrice()); redEnvelopeRefDO.setType(TYPE_AUDITOR); redEnvelopeRefDO.setRedEnvelopeItemId(redEnvelopeItemDO.getId()); redEnvelopeRefDO.setApplyUserId(applyUserDO.getId()); redEnvelopeRefDO.setUserId(applyUserDO.getUserId()); redEnvelopeRefDAO.save(redEnvelopeRefDO); redEnvelopeItemDO.setStatus(ITEM_STATUS_DONE); redEnvelopeItemDAO.update(redEnvelopeItemDO); &#125;); grabRedEnvelopeInfoVO.setGain(true); grabRedEnvelopeInfoVO.setType(GAIN.getType()); grabRedEnvelopeInfoVO.setPrice(redEnvelopeItemDO.getPrice()); ... return RpcResponse.success(grabRedEnvelopeInfoVO); 这里有什么问题，问题就出在存在多处不严谨： findById后返回的redEnvelopeItemDO对象竟然没判空。如果说创建红包时，能够确认存子红包到数据库成功后再Rpush到子红包id缓存List，我觉得都没有问题。问题就是，创建红包时，并没有关注新增子红包后的返回值就直接写Redis了。这种情况下，很有可能在redis中写入了一个不存在的红包id。 如果去除了一个不存在的红包id，好吧，也罢。事务中肯定会报NPE，事务一定会失败。但为何后续也不关注事务的返回结果就直接设置接口响应的VO，标记已经抢红包成功了，并返回了结果？？？这将会直接导致用户端展示为抢红包成功了，但根本看不到自己抢了多少钱… 优化后如下，具体关键步骤逻辑如注释描述： 123456789101112131415161718192021222324252627282930313233343536373839RedEnvelopeItemDO redEnvelopeItemDO = redEnvelopeItemDAO.findById(Long.parseLong(redEnvelopeItemIdStr));//先对redEnvelopeItemDO判空，不为空，说明子红包表才是真的存在这么一个红包 if (Objects.isNull(redEnvelopeItemDO)) &#123; grabRedEnvelopeInfoVO.setType(NO_GAIN.getType()); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125;//关注事务的返回结果 boolean transaction = jdbcDAO.withTransaction(() -&gt; &#123; RedEnvelopeRefDO redEnvelopeRefDO = new RedEnvelopeRefDO(); redEnvelopeRefDO.setPrice(redEnvelopeItemDO.getPrice()); redEnvelopeRefDO.setType(TYPE_AUDITOR); redEnvelopeRefDO.setRedEnvelopeItemId(redEnvelopeItemDO.getId()); redEnvelopeRefDO.setApplyUserId(applyUser.getId()); redEnvelopeRefDO.setUserId(applyUser.getUserId()); int saveRes = redEnvelopeRefDAO.save(redEnvelopeRefDO); //保存完红包明细记录后，也要关注返回结果，如果不成功，需要主动抛出异常 if (!Objects.equals(CONST_1, saveRes)) &#123; //如果没保存ref成功,抛异常使事务失败 throw new RuntimeException(&quot;创建红包明细失败～&quot;); &#125; redEnvelopeItemDO.setStatus(ITEM_STATUS_DONE); int updateRes = redEnvelopeItemDAO.update(redEnvelopeItemDO); //更新子红包状态不成功，也需要主动抛出异常 if (!Objects.equals(CONST_1, updateRes)) &#123; //如果更新红包项状态失败，抛异常使事务失败 throw new RuntimeException(&quot;更新红包项状态失败～&quot;); &#125; &#125;); if (!transaction) &#123; //事务失败了，那就是抢红包失败了，此时子红包缓存list中此id被消耗掉了也无所谓 grabRedEnvelopeInfoVO.setType(NO_GAIN.getType()); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; //将此已经抢成功的红包id记录到缓存，用于下一次接口请求进来判断，今天是否已经抢成功三次了，当前红包是否已经抢过了 recordGrabSuccess(userId, redEnvelopeId); grabRedEnvelopeInfoVO.setGain(true); grabRedEnvelopeInfoVO.setType(GAIN.getType()); grabRedEnvelopeInfoVO.setPrice(redEnvelopeItemDO.getPrice()); 至此，对与抢红包这个接口就算时基本优化完成了。目前从整体接口逻辑来看，我们做了的优化如下： 业务逻辑 优化前 优化后 好处 查询是否报名成功 SQL查询报名表 查询缓存 性能提升 查询一天成功抢红包的次数 SQL查询 查询一次缓存 性能提升 查询是否已经抢过了当前红包 SQL查询 利用上面的缓存查询结果即可 性能提升 获取一个子红包id LPOP LPOP（不变） 不变 查询子红包Id缓存List的剩余长度 LLEN 省略此次查询 性能提升 分布式锁 锁位置不对，不一定能释放，锁带有超时时间，线程自旋获取锁，影响接口吞吐量 优化锁位置，不自旋等待，获取不到锁直接返回 性能提升 记录红包明细，更细子红包状态 子红包在表中和缓存中数据可能不一致，并且没有关心事务结果 保证子红包在表中和缓存的一致性，关心事务结果 可靠性提升 经过这么一番优化后，结果的性能提升是可以预估的。几乎所有的读操作全都打到了缓存上。而真正能写次数最多只有红包设定的子红包个数次。 六、总结​ 这样就算优化完了吗？当然还没有！对于高并发的处理，接口仅仅是比较重要的一步罢了。在后续的文章中，我将继续从其他角度对此项目进行优化。","categories":[{"name":"高并发项目","slug":"高并发项目","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/"},{"name":"系列文章","slug":"高并发项目/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"红包","slug":"红包","permalink":"https://sombreknight.gitee.io/tags/%E7%BA%A2%E5%8C%85/"},{"name":"高并发","slug":"高并发","permalink":"https://sombreknight.gitee.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"性能优化","slug":"性能优化","permalink":"https://sombreknight.gitee.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}]},{"title":"《高并发红包炸弹项目性能优化》系列二：方案设计","slug":"0z9h4N46Yu0gPPfg","date":"2021-01-14T01:52:38.000Z","updated":"2021-01-14T01:52:05.000Z","comments":true,"path":"2021/01/14/0z9h4N46Yu0gPPfg/","link":"","permalink":"https://sombreknight.gitee.io/2021/01/14/0z9h4N46Yu0gPPfg/","excerpt":"","text":"一、开端​ 在上一篇文章《高并发红包炸弹项目性能优化》系列一：项目介绍 中，我介绍了下该红包项目的需求流程，以及一些此项目会涉及到的难点。这一篇文章，主要介绍针对此红包炸弹需求，我们的方案是如何设计的。由于项目是1.0版上线之后才交接到我手上的，因此方案并非我牵头设计的。但是对于别人的设计，我们还是可以怀着自己的思想去审视下，此方案的好坏，以及是否可以进一步优化。 二、方案设计前的思考​ 1. 首先我们对此项目有一个整体的交互模型，如下图所示, 管理员负责发红包，用户负责抢红包； 发红包最需要考虑的事情 发红包后用户抢到的子红包是提前生成好，还是用户抢的时候实时计算能抢多少？（离线计算还是实时计算？） 投放的红包炸弹在炸开前1分钟，如何通知到用户端，让用户端展示出红包炸弹倒计时？（推还是拉？） 怎样设计让一个红包拆分出的子红包能够具备一定的分布特性（如正态分布），使用户抢到的单个子红包金额在一个控制返回？（单个子红包不能太大，也不能太小） 抢红包最需要考虑的事情 如何应对瞬时高并发请求，怎样保护服务器，怎样保护DB？（羊毛党可能只是为了抢到红包，但黑客可能只是单纯地想把你的服务器打挂） 如何防止超抢？即所有用户抢到的子红包之和应该小于等于红包总金额； 正常用户和黑客一起抢红包，黑客利用技术手段可以更及时的在红包炸弹爆开的一瞬间发起请求，如何识别非正常的请求？如何保证正常用户都能够公平的参与竞争？ 三、看看别人的方案设计1. 数据库表设计​ 如下图所示，是为满足红包炸弹相关需求所设计的表结构： 红包炸弹相关的有三张表： 红包表 ： 记录了谁在什么时间投放了一个红包炸弹,该红包炸弹的金额，可拆分的子红包数目，红包的炸开时间，红包的状态，以及记录了此红包什么时间被抢完; 子红包表: 记录了当前子红包属于哪个红包，当前子红包的金额，当前子红包的状态; 红包明细表：记录了哪个用户，在什么时间抢了一个怎样的子红包，明细表中冗余了子红包金额字段 支持红包炸弹的一张业务表： 报名记录表：记录了用户的报名信息和状态，相对于红包炸弹来讲，需要满足”用户报名成功才能抢红包“。 2. 消息通知流程整个红包炸弹需要进行消息通知的有这么几处地方： 后台创建了红包炸弹，用户端需要收到通知，然后在页面展示有一个红包炸弹即将在某个时间点炸开； 当距离红包炸弹炸开前1分钟时，用户端需要收到通知，然后在页面开始红包炸弹炸开的60秒倒计时； 当红包炸弹被管理员取消，或者红包炸开后15s用户没有抢完子红包，系统自动将红包置完成时，会通知用户端，红包已失效或者进入红包历史界面； 基于公司的中台IM系统（依赖第三方云服务即时通信），可以进行消息的及时下发，采用的是长链接的方式。 3. 前端请求限流当红包炸弹60秒倒计时完成，就可以点击红包云朵，进行抢红包了。这里为了限制请求，前端做的处理是，必须在发起一次抢红包接口返回后，才能发起下一次请求。目前用户端分别做了小程序版和H5版。很明显这种请求限流方式，在H5方案情况下，如果用户开多个浏览器，多个Tab窗口进行同时请求，是拦截不住的。这里我让前端做了一些优化，因为H5页面最终是嵌套在客户端内打开的，所以只要在判断当前环境是在客户端才能进行请求即可。单独抓包H5页面在浏览器是无法请求接口的。 4. 服务端核心接口逻辑实现申明：先申明下以下代码并非我写的，而是此红包项目交接到我手里时的代码。代码的问题多，后续我将会对这些代码进行针对性的问题优化，我们先只关注业务主流逻辑，我在其源码上加了必要的注释方便大家看懂，暂不要关心代码的严谨性和性能等问题 1）创建红包 创建红包接口逻辑大概如下： 12345678910111213141516@ApiOperation(value = &quot;后台创建红包炸弹&quot;)@PostMapping(&quot;/createForAuditor&quot;)@ValidateBodypublic RpcResponse&lt;String&gt; createForAuditor(@RequestBody CreateRedEnvelopeVO createRedEnvelopeVO)&#123; //省略一些基本条件校验逻辑 String redisLock = &quot;createForAuditor&quot; + inspectId; //获取分布式锁 redisLocker.lock(redisLock); //创建红包 redEnvelopeLogic.create(num, price, inspectId, TYPE_AUDITOR, startTime); //通过IM通知用户端，红包已经创建了，用户端收到通知后将会在页面显示一个红包炸弹将在什么时间开爆 redEnvelopeLogic.sendNoticeToIM(redEnvelopeDAO.queryLatestRedEnvelope(), CelebrationConstants.Hdf_Celebration_Bomb); //释放锁 redisLocker.unlock(redisLock); return RpcResponse.success(&quot;创建成功&quot;); &#125; 看下上面第10行里调用的创建红包的核心逻辑 123456789101112131415161718private void create4Auditor(Integer num, BigDecimal price, Long inspectId, HaoDate startTime) &#123; RedEnvelopeDO redEnvelopeDO = new RedEnvelopeDO(); redEnvelopeDO.setNum(num); redEnvelopeDO.setSourceId(inspectId); //红包的类型还有其他多种，这个类型代表时红包炸弹 redEnvelopeDO.setSourceType(RedEnvelopeConstants.TYPE_AUDITOR); redEnvelopeDO.setPrice(price); redEnvelopeDO.setStatus(RedEnvelopeConstants.STATUS_VALID); redEnvelopeDO.setTime(startTime); //保存红包到数据库 redEnvelopeDAO.save(redEnvelopeDO); //异步创建子红包 celebrationMqProcessor.sendCreateRedEnvelopeItem(redEnvelopeDO); //创建一个延迟MQ消息，在红包炸开后15s自动置红包炸弹完成 celebrationMqProcessor.sendAutoComplete(redEnvelopeDO); //创建一个延迟MQ消息，在红包炸开前1分钟，通知用户端，开始60s倒计时 celebrationMqProcessor.sendCountDownMsg(redEnvelopeDO); &#125; 可以看出，这里是提前创建好子红包的，我们来看下子红包是如何生成的 12345678910111213141516171819202122232425//createItems此方法已经是在MQ的消费者线程中执行的了public boolean createItems(RedEnvelopeMessage message)&#123; log.info(&quot;MQ Monitor createItems msg: &#123;&#125;&quot;, message); RedEnvelopeDO redEnvelopeDO = redEnvelopeDAO.findById(message.getRedEnvelopeId()); if(redEnvelopeDO == null)&#123; return true; &#125; //这里给价格乘以了100，看起来意思是把元/角/分的分单位整数化 Integer totalAmount = redEnvelopeDO.getPrice().intValue() * 100; Integer num = redEnvelopeDO.getNum(); //可以知道就是这个工具方法，把一个红包分成了指定份数的子红包 List&lt;Integer&gt; redEnvelopeList = RedEnvelopeUtil.divideRedEnvelope(totalAmount, num); redEnvelopeList.forEach(integer -&gt; &#123; RedEnvelopeItemDO redEnvelopeItemDO = new RedEnvelopeItemDO(); redEnvelopeItemDO.setRedEnvelopeId(redEnvelopeDO.getId()); redEnvelopeItemDO.setPrice(BigDecimal.valueOf((double) integer / 100)); redEnvelopeItemDO.setStatus(ITEM_STATUS_DOING); redEnvelopeItemDO.setDescription(&quot;红包炸弹&quot;); //子红包存库 redEnvelopeItemDAO.save(redEnvelopeItemDO); //把子红包的id Rpush到了redis的一个list redisClient.rpush(RED_ENVELOPE_ITEM_KEY + redEnvelopeDO.getId(), String.valueOf(redEnvelopeItemDO.getId())); &#125;); return true; &#125; 拆分红包为若干子红包的工具方法逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 生成红包一次分配结果 * @param totalAmount 总红包量 * @param totalNum 总份数 * @return List&lt;Integer&gt; */public static List&lt;Integer&gt; divideRedEnvelope(Integer totalAmount, Integer totalNum) &#123; //这个sendedAmount变量原作者应该是想表达，已经生成的红包消耗了多少钱了 Integer sendedAmount = 0; //这个sendedNum变量原作者应该是想表达，已经生产几个红包了 Integer sendedNum = 0; //这里min应该代表一个子红包最低应该是平均子红包金额的十分之一 int min = (totalAmount / totalNum ) / 10; //rdMin代表红包最低的真实价格，如果算出来min==0了，最少也要为1，此时单位应该是分，即子红包最小1分钱 Integer rdMin = min == 0 ? 1 : min; //rdMax代表子红包最大为平均值的2倍 Integer rdMax = (totalAmount / totalNum * 2); List&lt;Integer&gt; redEnvelope = new ArrayList&lt;&gt;(); while (sendedNum &lt; totalNum) &#123; //循环的计算每个子红包的价格，子红包价格区间在【1分，2倍平均红包的价格】 Integer bonus = randomOneRedEnvelope(totalAmount, totalNum, sendedAmount, sendedNum, rdMin, rdMax); redEnvelope.add(bonus); sendedNum++; sendedAmount += bonus; &#125; //返回由计算出来的子红包金额组成的List return redEnvelope;&#125;/** * 随机分配第n个红包 * @param totalAmount 总红包量 * @param totalNum 总份数 * @param sendedAmount 已发送红包量 * @param sendedNum 已发送份数 * @param rdMin 随机下限 * @param rdMax 随机上限 * @return Integer */private static Integer randomOneRedEnvelope(Integer totalAmount, Integer totalNum, Integer sendedAmount, Integer sendedNum, Integer rdMin, Integer rdMax) &#123; Integer boundMin = Math.max((totalAmount - sendedAmount - (totalNum - sendedNum - 1) * rdMax), rdMin); Integer boundMax = Math.min((totalAmount - sendedAmount - (totalNum - sendedNum - 1) * rdMin), rdMax); return getRandomVal(boundMin, boundMax);&#125;/** * 返回min~max区间内随机数，含min和max * @param min * @param max * @return Integer */private static int getRandomVal(int min, int max) &#123; return rand.nextInt(max - min + 1) + min;&#125; 2）抢红包 抢红包主接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106@GetMapping(&quot;/grabRedEnvelopes&quot;) @ApiOperation(value = &quot;抢红包接口&quot;, notes = &quot;userId 用户Id | redEnvelopeId：红包id&quot;) public RpcResponse&lt;GrabRedEnvelopeInfoVO&gt; grabRedEnvelopes(@RequestParam Long userId, @RequestParam Long redEnvelopeId)&#123; //空参校验 if(!ObjectUtils.allNotNull(userId, redEnvelopeId))&#123; return RpcResponse.error(ErrorCode.PARAMS_EXCEPTION); &#125; //校验红包是否存在，公司的当前基础服务框架中，DAO查询的findById方法会查询实体缓存 //实体缓存存放于redis中，如果实体缓存失效了，会去查询MySQL集群中的主库 RedEnvelopeDO redEnvelopeDO = redEnvelopeDAO.findById(redEnvelopeId); if(null == redEnvelopeDO)&#123; return RpcResponse.error(ErrorCode.PARAMS_EXCEPTION); &#125; //校验是否红包还没开爆，还没开爆就进来抢红包的，肯定要拦截 if(HaoDate.currentTimeSecond() - redEnvelopeDO.getTime().getTimeSecond() &lt; 0)&#123; return RpcResponse.error(ErrorCode.RED_NO_BEGAIN); &#125; //判断红包是否已经被取消了，如果已经取消了，也是抢不了的 if(ObjectUtils.notEqual(STATUS_VALID,redEnvelopeDO.getStatus()))&#123; return RpcResponse.error(ErrorCode.RED_BE_OVER); &#125; //构造结构返回的VO，gain字段表示是否抢到了红包 GrabRedEnvelopeInfoVO grabRedEnvelopeInfoVO = GrabRedEnvelopeInfoVO.builder().gain(false).userId(userId).build(); //获取分布式锁 String lockName = &quot;celebration_&quot; + userId; //这里用了tryLock，本质上是一个带超时返回的自旋锁 boolean isUserLock = redisLocker.tryLock(lockName, 5, 5); if(!isUserLock)&#123; //超时都没拿到锁，就返回请稍后重试 return RpcResponse.error(ErrorCode.NO_GET_LOCK_TIP); &#125; //判断有没有报名，这个getApplyUserByUserId接口逻辑是查询报名表，是否有报名成功的记录，此接口没有做缓存 ApplyUserDO applyUserDO = applyUserLogic.getApplyUserByUserId(userId); if(null == applyUserDO) &#123; //提示没报名，释放锁 grabRedEnvelopeInfoVO.setType(NO_SIGN_UP.getType()); redisLocker.unlock(lockName); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; //判断是否已经抢过当前红包了，这里Dao层查询了红包明细表，但是红包明细表中没有红包id，只有子红包id //所以这里连表查询了，这个dao方法一会儿放在下面的代码块中 Long redEnvelopeRefId = redEnvelopeRefDAO.getRedEnvelopeRef(redEnvelopeId, userId); if(null != redEnvelopeRefId)&#123; //如果已经抢过此红包了，就提示已抢过并释放锁，接口返回 grabRedEnvelopeInfoVO.setType(ALREADY_GAIN.getType()); redisLocker.unlock(lockName); return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; //判断一天内是否已经抢过三次 //这个dao查询方法一会儿也放在下面的代码块中 List&lt;RedEnvelopeRefDO&gt; redEnvelopeRefDOList = redEnvelopeRefDAO.getRedEnvelopeRefList(userId); if(redEnvelopeRefDOList.size() &gt;= overLimit)&#123; //如果已经抢过三次了，则提示您已经三连冠了，把机会让给别人吧。 grabRedEnvelopeInfoVO.setType(OVER_GAIN.getType()); //释放分布式锁 redisLocker.unlock(lockName); //接口返回 return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; try &#123; //从redis中Lpop一个子红包id出来，这个是在创建子红包时Rpush进入这个list的 //这里进行了id转换，如果抛NumberFormatException异常了，则说明list中已经空了 //代表红包已经被抢完了，在catch中处理了抢完的逻辑 Long redEnvelopeItemId = Long.valueOf(redisClient.lpop(RED_ENVELOPE_ITEM_KEY + redEnvelopeDO.getId())); log.info(&quot;redis itemId:&#123;&#125;&quot;,redisClient.lrange(RED_ENVELOPE_ITEM_KEY + redEnvelopeDO.getId(), 0, -1).toString()); //这里llen查询了下redis中存放子红包id的list长度，如果空了，并且当前红包还没有置完成，就直接给红包置完成了 if(!ObjectUtils.notEqual(0L,redisClient.llen(RED_ENVELOPE_ITEM_KEY + redEnvelopeDO.getId())) &amp;&amp; HaoDate.isZeroTime(redEnvelopeDO.getCompleteTime()))&#123; redEnvelopeDO.setCompleteTime(new HaoDate()); redEnvelopeDAO.update(redEnvelopeDO); &#125; //这里根据拿到的子红包id查询子红包实体。findById会先查询实体缓存，没有就查主库 RedEnvelopeItemDO redEnvelopeItemDO = redEnvelopeItemDAO.findById(redEnvelopeItemId); //开启事务，创建红包明细，更新子红包状态为完成，代表已经抢成功了。这里居然没关心事务返回结果，后面也会优化处理 jdbcDAO.withTransaction(()-&gt;&#123; RedEnvelopeRefDO redEnvelopeRefDO = new RedEnvelopeRefDO(); redEnvelopeRefDO.setPrice(redEnvelopeItemDO.getPrice()); redEnvelopeRefDO.setType(TYPE_AUDITOR); redEnvelopeRefDO.setRedEnvelopeItemId(redEnvelopeItemDO.getId()); redEnvelopeRefDO.setApplyUserId(applyUserDO.getId()); redEnvelopeRefDO.setUserId(applyUserDO.getUserId()); redEnvelopeRefDAO.save(redEnvelopeRefDO); redEnvelopeItemDO.setStatus(ITEM_STATUS_DONE); redEnvelopeItemDAO.update(redEnvelopeItemDO); &#125;); //设置接口返回的VO中Gain为true，表示抢成功了 grabRedEnvelopeInfoVO.setGain(true); grabRedEnvelopeInfoVO.setType(GAIN.getType()); grabRedEnvelopeInfoVO.setPrice(redEnvelopeItemDO.getPrice()); &#125;catch (NumberFormatException e)&#123; //如果这里捕获到异常，说明从redis的list取空了，设置为抢失败 grabRedEnvelopeInfoVO.setType(NO_GAIN.getType()); //更新红包的完成时间 if(HaoDate.isZeroTime(redEnvelopeDO.getCompleteTime())) &#123; redEnvelopeDO.setCompleteTime(new HaoDate()); redEnvelopeDAO.update(redEnvelopeDO); &#125; //接口返回 return RpcResponse.success(grabRedEnvelopeInfoVO); &#125;finally &#123; //这里释放锁，但时就目前这个代码严谨程度上看，还真不一定能及时释放掉这个锁，后面会讲我是怎么优化的 redisLocker.unlock(lockName); &#125; //接口返回vo return RpcResponse.success(grabRedEnvelopeInfoVO); &#125; 上面第43行的dao查询方法getRedEnvelopeRef，具体实现如下 123456789101112public Long getRedEnvelopeRef(@NotNull Long redEnvelopeId, @NotNull Long userId)&#123; //看这个sql是要连接redenvelopes红包表、redenvelopeitems子红包表、redenveloperefs红包明细表三表连接查询当前用户是否已经抢过这个红包了 //这个sql过于复杂了，而且性能不高，连起码的limit 1都没有加上，后面讲如何优化掉这个多表查询 String sql = &quot;select c.id from redenvelopes a inner join redenvelopeitems b on a.id = b.redenvelopeid inner join &quot; + &quot;redenveloperefs c on b.id = c.redenvelopeitemid where c.userid = :userId and a.id = :redEnvelopeId &quot; + &quot;and b.status = :status and a.sourcetype = :sourceType&quot;; SqlParam sqlParam = SqlParam.create(&quot;userId&quot;, userId). add(&quot;redEnvelopeId&quot;, redEnvelopeId). add(&quot;status&quot;, ITEM_STATUS_DONE). add(&quot;sourceType&quot;, TYPE_AUDITOR); return jdbcDAO.findField(Long.class, sql, sqlParam); 上面第52行dao查询方法getRedEnvelopeRefList，具体实现如下 12345678910111213public List&lt;RedEnvelopeRefDO&gt; getRedEnvelopeRefList(@NotNull Long userId)&#123; //可以看出来就是查询了所有的这一天时间短内，这个用户抢了这类型的红包记录 //直接返回了明细的DO，这里最起码的优化返回主键id列表或者sql Count一下就可以了。当然还有更好的优化。 String whereSql = &quot;where userid = :userId and type =:type and ctime &gt;= :startTime and ctime &lt;= :endTime&quot;; HaoDate now = new HaoDate(); String startTime = now.dateString(); String endTime = now.offsetDay(1).dateString(); SqlParam sqlParam = SqlParam.create(&quot;userId&quot;, userId). add(&quot;type&quot;, TYPE_AUDITOR). add(&quot;startTime&quot;, startTime). add(&quot;endTime&quot;, endTime); return jdbcDAO.findList(RedEnvelopeRefDO.class, whereSql, sqlParam); &#125; 通过上面几段最核心的代码，大概能看出来这些问题了。 代码不规范，比如很多地方不关心返回值，理所应当的认为调用成功 逻辑不严谨，像使用分布锁的地方，加锁地方和最终try…finally…的代码短隔了很多中间逻辑，无法保证一定就能进入try代码块，更无法保证一定会释放锁了 性能问题很多，使用缓存的地方，除了公司dao层框架提供的实体缓存和分布式锁，就没有别的地方使用缓存了。大量的查询库表，甚至出现多表连接的复杂SQL。在应对抢红包这样大并发的情况下，显然是不够的。 安全性问题： 锁的力度小（锁用户），不同用户并发进来，没有任何阻碍，无法很好做到限流 使用了tryLock带超时的自旋锁，当发生恶意攻击时，可能一个用户就把所有机器的线程打满了，服务就不能提供给其他人了 接口整体没有限流，不能做到削峰填谷，流量洪峰下，可能打挂服务，也可能打挂DB 框架的dao层查询实体缓存是OK的，但是不能解决缓存穿透的问题。恶意用户一直使用不存在的userId请求的话，会给DB造成很大的压力 还有更多的问题就不一一列举了，在后面的文章中，我将一步步的优化代码、优化前后端交互流程、使用一些限流/熔断/降级、压力测试等手段一步步将这个抢红包项目彻底优化，以能够应付各种高并发下的问题。 四、总结这里篇文章里，我对红包炸弹交接前的设计方案、核心实现等做了一些介绍，在后面的文章中我将正式开始一步步地去优化这个项目。","categories":[{"name":"高并发项目","slug":"高并发项目","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/"},{"name":"系列文章","slug":"高并发项目/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"红包","slug":"红包","permalink":"https://sombreknight.gitee.io/tags/%E7%BA%A2%E5%8C%85/"},{"name":"高并发","slug":"高并发","permalink":"https://sombreknight.gitee.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"性能优化","slug":"性能优化","permalink":"https://sombreknight.gitee.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}]},{"title":"《高并发红包炸弹项目性能优化》系列一：项目介绍","slug":"MRWloLteKJcf5Idr","date":"2021-01-13T15:06:44.000Z","updated":"2021-01-13T15:07:12.000Z","comments":true,"path":"2021/01/13/MRWloLteKJcf5Idr/","link":"","permalink":"https://sombreknight.gitee.io/2021/01/13/MRWloLteKJcf5Idr/","excerpt":"","text":"一、项目介绍​ 受疫情影响，公司打算在今年搞一次全国医生线上年会。而公司为了或是引流、或是给医生分福利，计划设计一个砸钱抢红包的环节。运气非常不错，虽然整体方案最初的设计不是我做的，但是最后此红包项目的性能优化却落到了我这里。平常的业务项目里，大多接触不到高并发场景，故借此机会，对此项目进行一个好好优化梳理，相信一定会对自己大有裨益的。 首先介绍下抢红包的流程，如下图所示： 首先是年会活动主会场界面，如下图一所示，右下角展示的就是红包炸弹，当有炸弹即将在1分钟后爆开时，就会进入此60秒倒计时。当倒计时完成时界面出现抢红包的云朵图案，如下图二所示。 当点击抢红包云朵图案时，有一下情况： 用户没有报名参加年会，是无法参与抢红包的，会提示还没报名，并引导用户去报名页面，如下图一所示； 用户点击云朵，但是没有抢到红包，提示手慢了，如下图二所示； 用户点击云朵，成功抢到了，点击开红包，查看红包明细，如下图三所示； 用户点击云朵，系统检测出来该用户今天已经成功抢到三次红包了，提示已经3连冠，把机会让给别人。如下图四所示。 用户点击云朵，系统检测出来该用户已经抢成功过了当前红包，直接进入红包明细，如下图五所示。 后台投放红包很简单，管理员可以在后台投放红包炸弹，指定什么时候炸开，投放的红包会分成多少份，总金额是多少。如下图所示： 产品的一些关键特殊的要求，汇总如下： 一个红包炸开了，最多抢15s，这个红包就会被自动置完成，用户不能再抢了 一个用户一天最多抢成功3个红包 一个红包，同一用户最多只能抢成功一次 管理员随时可以在后台取消红包 至此，相信大家对此项目已经有了一定的基本了解。我再附上一张流程图更好的说明整个流程。 二、难点分析这个项目是有一定难度的，具体难在哪儿，我个人的看法如下： 公司的医生用户基数大，年会报名人数预计在30万+，年会当晚会持续多轮红包炸弹轰炸，平均QPS约为在30w/15s = 2000，但是抢红包的这15s不可能每一秒钟都qps都是均衡的，预计峰值QPS可能达到30w/5s = 6000左右，也就是预计在红包炸弹炸开的前5sQPS应该是最高的时候。查阅资料 可知，如微博每天1亿多pv的系统一般也就1500QPS，5000QPS峰值。但是具体多少QPS跟业务强相关，只读接口读缓存，将压力给到缓存单机3000+没问题，写请求1000+也正常，也复杂些可能也就几百+QPS。 如此高的并发下，我们很容易在服务层面想到加机器，但是最应该保护的其实是DB。如果一个红包分成了1000个子红包，这意味着抢完这个红包最多要写库1000次。感觉写库的量并不大，但是要知道的是，这1000次写库非常集中，瞬时写库会给DB造成比较大的压力，可能导致并发下其他查询事务受到影响，甚至影响到其他业务。故我们需要对必要的接口进行流量控制以保证接口的吞吐量维持在一个较高的位置，但是又不会直接影响到服务性能。 并发下，如何保证不“超抢”。例如其实只发了1万元红包，不能因为并发原因，就让用户抢出去2万块钱了。底线应该是，宁可让用户抢不到，也不能抢超了。 怎样避免羊毛党，恶意刷接口等操作造成公司利益受损？ 三、总结好了，到这里我们先对此项目有个整体上的感知即可。 抢红包面向医生群体，数量约30w+；抢红包需要先报名；一天最多抢成功三次；同一红包只能抢成功一次。 下一篇文章具体介绍下这个项目的数据库表设计，以及他们的接口代码实现。","categories":[{"name":"高并发项目","slug":"高并发项目","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/"},{"name":"系列文章","slug":"高并发项目/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"红包","slug":"红包","permalink":"https://sombreknight.gitee.io/tags/%E7%BA%A2%E5%8C%85/"},{"name":"高并发","slug":"高并发","permalink":"https://sombreknight.gitee.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"性能优化","slug":"性能优化","permalink":"https://sombreknight.gitee.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}]},{"title":"博客计划","slug":"f2hoimvLZitLtDEL","date":"2021-01-10T05:26:20.000Z","updated":"2021-01-10T05:08:31.000Z","comments":true,"path":"2021/01/10/f2hoimvLZitLtDEL/","link":"","permalink":"https://sombreknight.gitee.io/2021/01/10/f2hoimvLZitLtDEL/","excerpt":"","text":"基础系列 数据结构之树系列 算法系列（贪心、回溯、动态规划） 操作系统系列（操作系统基础、UNIX基础） 计算机网络系列（IP协议、TCP协议、HTTP协议） Java系列 Java语言基础 Java集合框架（包含并发集合框架） Java多线程与高并发（锁、AQS、阻塞队列等） JVM系列（对象头、GC、JVM调优） Web框架系列 Spring框架（IOC、AOP、事务） SpringMVC框架（请求分发流程） SpringBoot(自动配置原理) SpringCloud系列 Eureka Ribbon OpenFeign Hystrix GateWay SpringCloud Alibaba系列 Nacos Sentinel Dubbo Seata 数据库系列 MySQL（SQL优化、锁、底层索引原理、分库分表、高可用） MongoDB ElasticSearch 中间件系列 Redis（数据结构、缓存/分布式锁/限流器等应用、缓存穿透/击穿/雪崩概念和解决方案、日志、主从/哨兵/集群） Zookeeper(基本使用、ZAB协议基本原理、高可用方案) RabbitMQ(基本概念和使用、高可用方案) Kafka（基本概念和使用、高可用方案） 软件工程系列 设计模式（结合Spring框架中的案例） 代码整洁之道 重构 领域对象模型 开源项目系列 手写Spring框架 增强Jedis框架，支持可重入、可续期、高可用的分布式锁 基于RestTemplate的一个Rpc框架，且支持全链路监控、支持限流/熔断/降级、支持同步/异步调用 基于JdbcTemplate的一个Dao框架，支持乐观锁、支持单机一级和Redis二级实体缓存","categories":[{"name":"博客计划","slug":"博客计划","permalink":"https://sombreknight.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"博客计划","slug":"博客计划","permalink":"https://sombreknight.gitee.io/tags/%E5%8D%9A%E5%AE%A2%E8%AE%A1%E5%88%92/"}]}],"categories":[{"name":"Java","slug":"Java","permalink":"https://sombreknight.gitee.io/categories/Java/"},{"name":"虚拟机","slug":"Java/虚拟机","permalink":"https://sombreknight.gitee.io/categories/Java/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"中间件","slug":"中间件","permalink":"https://sombreknight.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"系列文章","slug":"中间件/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"},{"name":"高并发项目","slug":"高并发项目","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/"},{"name":"系列文章","slug":"高并发项目/系列文章","permalink":"https://sombreknight.gitee.io/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%A1%B9%E7%9B%AE/%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"},{"name":"博客计划","slug":"博客计划","permalink":"https://sombreknight.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://sombreknight.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://sombreknight.gitee.io/tags/JVM/"},{"name":"中间件","slug":"中间件","permalink":"https://sombreknight.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"Redis","permalink":"https://sombreknight.gitee.io/tags/Redis/"},{"name":"红包","slug":"红包","permalink":"https://sombreknight.gitee.io/tags/%E7%BA%A2%E5%8C%85/"},{"name":"高并发","slug":"高并发","permalink":"https://sombreknight.gitee.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"性能优化","slug":"性能优化","permalink":"https://sombreknight.gitee.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"博客计划","slug":"博客计划","permalink":"https://sombreknight.gitee.io/tags/%E5%8D%9A%E5%AE%A2%E8%AE%A1%E5%88%92/"}]}